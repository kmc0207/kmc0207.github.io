---
layout: post
title: "Lifelong Language Learning이란?"
categories : 
 - Explain
tags : 
 - NLP, Lifelong learning
---  
  
# Lifelong Language Learning
**Lifelong Language Learning**(LLL)은 한국어 번역 그대로, Language Model(LM)을 계속해서 학습시키고자 하는 목적을 가지고 연구하는, 자연어 처리의 한 분야라고 할 수 있다.  
현재 BERT나 GPT를 필두로 Transformer 기반 Language Model이 여러가지 Down-Stream Task에서 좋은 성적을 내고 있다.  
하지만 이들에게는 치명적인 문제가 있다. 그것은 현재의 Transformer 기반 LM은 '평생' 학습을 할 수 없다는 것이다.  
LM이 Corpus 1에서 Task1에 대한 Training을 하고, 80%의 Test accuracy를 가지고 있다. 
여기서 LM이 Corpus2에서 Task2에 대한 Training을 진행하게 된다면 어떻게 될까?  
LM은 Task2에서는 좋은 성적을 낼 수 있지만, Task1에서는 매우 낮은 성능을 기록하게 된다. 약 30%~50%의 accuracy를 가지게 된다.
이는 Task1과 Task2가 같아도, Corpus1과 Corpus2가 같은 Domain의 Corpus라도 동일하게 나타난다.
물론, Task가 서로 같고, Domain이 서로 같으면 훨씬 성능이 덜 떨어지게 된다.  
하지만 그럼에도 성능의 저하가 나타나게 된다. Task가 다르고, Domain도 다르다면 감소폭은 아주 크게 된다.  
Lifelong learning에서는 이 현상을 '**catastrophic forgetting**', 우리 말로 번역하자면 '대재앙적 망각'이라고 부른다.      
    
혹자는 Catastrophic Forgetting(CF)가 Model의 Capacity가 부족해서 일어난 일이 아닌가 생각할 수도 있겠다.
그런 생각을 하는 편이 더 합리적인 사람이라고 볼 수 있다. 하지만 그렇지는 않다. 
왜냐하면 Corpus1과 Corpus2를 같이 넣고 Training한 Multitask Model에서는 CF가 일어나지 않기 때문이다.  
  
  
이는 사실 자연어 처리든 컴퓨터 비전이든 다 겪고 있는 현상이며, 아주 핫한 연구 주제이다.  
만약 삼성전자가 인공지능 비서를 자연어 처리로 만든다고 생각해보자. 
이 비서를 사람들이 이용하면서 다양한 자연어가 오갈테고, 그에 따른 사용자의 피드백도 쌓여갈 것이다. 
그런데 이렇게 새로 쌓인 데이터를 모델에 넣으면, 지난번에 배운 내용을 까먹게 되는 것이다! 
결국 삼성전자는 울며 겨자먹기로 이때까지 모아온 데이터 + 원래 모델을 학습시킬 때 사용하는 데이터를 한번에 학습시켜야 한다. 
당연히 비용도 많이 들고, 발전 속도도 느려지게 될 것이다. 
영화에서 나오는 스스로 학습하는 인공지능! 은 아직까지 먼 미래라는 뜻이다.

    

  
그렇기 때문에 많은 연구자들이 이 CF를 해결하고자 노력을 하고 있다. 
특히 약인공지능이 점점 상업화에 가까워져가는 지금, Lifelong Learning의 문제가 해결되지 않으면 인공지능의 발전에 큰 걸림돌이 될 것이다.
아마 다음부터는 연구자들이 Lifelong Leanring에 대해서 어떤 해답을 내놓고 있는지, 어떤 연구들이 진행되고 있는지 논문들을 Review 해볼 생각이다. 
필자는 자연어 처리 초보 연구자기 때문에, 아마 자연어 처리에 관련된 논문 위주로 리뷰하게 될 것 같다.
